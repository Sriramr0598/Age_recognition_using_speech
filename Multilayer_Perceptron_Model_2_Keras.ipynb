{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4mPxN76-z26"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(r\"D:\\\\training_feature_arr_MLP.npy\")\n",
    "y_train = np.load(r\"D:\\\\training_labels_MLP.npy\")\n",
    "X_test = np.load(r\"D:\\\\testing_feature_arr_MLP.npy\")\n",
    "y_test = np.load(r\"D:\\\\testing_labels_MLP.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "dhINTZc5_F-b",
    "outputId": "cc0938c9-9d29-4328-ff4b-c1f4906991cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRIRAM\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# use LASSO technique to do some feature selection because there are 170 features\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# need to use the one with categories (not one hot encoded)\n",
    "# to do feature selection\n",
    "\n",
    "# read in the csv file and put it in a DataFrame.\n",
    "df_train = pd.read_csv(r\"E:\\\\audio_training_data_cleaned.csv\")\n",
    "\n",
    "# drop any null values we may have forgotten\n",
    "df_train = df_train.dropna(how='any',axis=0)\n",
    "\n",
    "y_train_classes = df_train['age']\n",
    "\n",
    "# to do feature selection, must convert categorical values to\n",
    "# numerical values\n",
    "replaced = {'teens':1,'twenties':2,'thirties':3,'fourties':4,'fifties':5,'sixties':6,\n",
    "            'seventies':7,'eighties':8}\n",
    "y_train_encoded = y_train_classes.replace(replaced)\n",
    "\n",
    "y_train_encoded = y_train_encoded.astype('int')\n",
    "\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X_train, y_train_encoded)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_train = model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1751
    },
    "colab_type": "code",
    "id": "1J-A3gDh_IbZ",
    "outputId": "a12ba947-4889-454c-c07f-8f2f26a0cda4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "73765/73765 [==============================] - 8s 112us/step - loss: 1.7226 - acc: 0.3158\n",
      "Epoch 2/50\n",
      "73765/73765 [==============================] - 7s 101us/step - loss: 1.5970 - acc: 0.3630\n",
      "Epoch 3/50\n",
      "73765/73765 [==============================] - 7s 101us/step - loss: 1.5146 - acc: 0.4046\n",
      "Epoch 4/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 1.4281 - acc: 0.4386\n",
      "Epoch 5/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 1.3344 - acc: 0.4789\n",
      "Epoch 6/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 1.2515 - acc: 0.5175\n",
      "Epoch 7/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 1.1725 - acc: 0.5525\n",
      "Epoch 8/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 1.1076 - acc: 0.5784\n",
      "Epoch 9/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 1.0464 - acc: 0.6060\n",
      "Epoch 10/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.9912 - acc: 0.6288\n",
      "Epoch 11/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 0.9415 - acc: 0.6479\n",
      "Epoch 12/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.8998 - acc: 0.6657\n",
      "Epoch 13/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 0.8644 - acc: 0.6812\n",
      "Epoch 14/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.8303 - acc: 0.6932\n",
      "Epoch 15/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.7996 - acc: 0.7037\n",
      "Epoch 16/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.7703 - acc: 0.7174\n",
      "Epoch 17/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 0.7471 - acc: 0.7264\n",
      "Epoch 18/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 0.7210 - acc: 0.7358\n",
      "Epoch 19/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 0.7042 - acc: 0.7405\n",
      "Epoch 20/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 0.6789 - acc: 0.7498\n",
      "Epoch 21/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.6653 - acc: 0.7571\n",
      "Epoch 22/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.6448 - acc: 0.7653\n",
      "Epoch 23/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.6358 - acc: 0.7672\n",
      "Epoch 24/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.6188 - acc: 0.7752\n",
      "Epoch 25/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.6041 - acc: 0.7797\n",
      "Epoch 26/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.5861 - acc: 0.7865\n",
      "Epoch 27/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.5771 - acc: 0.7892\n",
      "Epoch 28/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.5674 - acc: 0.7924\n",
      "Epoch 29/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.5632 - acc: 0.7943\n",
      "Epoch 30/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.5483 - acc: 0.8010\n",
      "Epoch 31/50\n",
      "73765/73765 [==============================] - 8s 106us/step - loss: 0.5310 - acc: 0.8072\n",
      "Epoch 32/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.5266 - acc: 0.8093\n",
      "Epoch 33/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.5126 - acc: 0.8139\n",
      "Epoch 34/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.5150 - acc: 0.8135\n",
      "Epoch 35/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.4985 - acc: 0.8184\n",
      "Epoch 36/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.4943 - acc: 0.8208\n",
      "Epoch 37/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.4884 - acc: 0.8229\n",
      "Epoch 38/50\n",
      "73765/73765 [==============================] - 8s 104us/step - loss: 0.4754 - acc: 0.8280\n",
      "Epoch 39/50\n",
      "73765/73765 [==============================] - 7s 97us/step - loss: 0.4738 - acc: 0.8280\n",
      "Epoch 40/50\n",
      "73765/73765 [==============================] - 7s 97us/step - loss: 0.4664 - acc: 0.8307\n",
      "Epoch 41/50\n",
      "73765/73765 [==============================] - 7s 97us/step - loss: 0.4565 - acc: 0.8352\n",
      "Epoch 42/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.4550 - acc: 0.8363\n",
      "Epoch 43/50\n",
      "73765/73765 [==============================] - 7s 97us/step - loss: 0.4452 - acc: 0.8398\n",
      "Epoch 44/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.4421 - acc: 0.8395\n",
      "Epoch 45/50\n",
      "73765/73765 [==============================] - 7s 98us/step - loss: 0.4342 - acc: 0.8440\n",
      "Epoch 46/50\n",
      "73765/73765 [==============================] - 7s 101us/step - loss: 0.4309 - acc: 0.8459\n",
      "Epoch 47/50\n",
      "73765/73765 [==============================] - 7s 101us/step - loss: 0.4253 - acc: 0.8473\n",
      "Epoch 48/50\n",
      "73765/73765 [==============================] - 7s 101us/step - loss: 0.4242 - acc: 0.8489\n",
      "Epoch 49/50\n",
      "73765/73765 [==============================] - 7s 100us/step - loss: 0.4170 - acc: 0.8520\n",
      "Epoch 50/50\n",
      "73765/73765 [==============================] - 7s 99us/step - loss: 0.4112 - acc: 0.8505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8863b68f50>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP model in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "DL_model = Sequential()\n",
    "\n",
    "DL_model.add(Dense(256, activation='relu'))\n",
    "DL_model.add(Dropout(0.2))\n",
    "\n",
    "DL_model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "DL_model.add(Dense(1024, activation='relu'))\n",
    "DL_model.add(Dropout(0.2))\n",
    "\n",
    "DL_model.add(Dense(256, activation='relu'))\n",
    "\n",
    "DL_model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "DL_model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "DL_model.fit(X_train,y_train,epochs=50,batch_size=100,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Hl3XpG5_LbV"
   },
   "outputs": [],
   "source": [
    "X_test = model.transform(X_test)\n",
    "DL_model.save('MLP_Model2.h5')\n",
    "from google.colab import files\n",
    "\n",
    "files.download('MLP_Model2.h5')\n",
    "\n",
    "# need to export X_train \n",
    "# with the selected features\n",
    "np.save('training_feature_arr_MLP_Model2.npy',X_train)\n",
    "files.download('training_feature_arr_MLP_Model2.npy')\n",
    "\n",
    "# need to export X_test with\n",
    "# the selected features\n",
    "np.save('testing_feature_arr_MLP_Model2.npy',X_test)\n",
    "files.download('testing_feature_arr_MLP_Model2.npy')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multilayer Perceptron Model 2 - Keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
